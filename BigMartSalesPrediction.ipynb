{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement \n",
    "\n",
    "In order to forecast the sales of each product at a specific store, BigMart Sales Prediction aims to comprehend the characteristics of products and how they interact with factors unique to each store.\n",
    "\n",
    "### Goal : \n",
    "\n",
    "Predict the sales of a product at a particular store so it would help :\n",
    "\n",
    "- enhance inventory management\n",
    "- increase sales \n",
    "- marketing decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Generation \n",
    "\n",
    "> Brainstorming the factors that affect the outcome.    \n",
    "\n",
    "- consumer behaviour : \n",
    "    - age , income and family size\n",
    "    - loyalty programs\n",
    "    - maketing campaigns\n",
    "    - online reviews\n",
    "\n",
    "- product :\n",
    "    - higher brand recognition ( higher sales )\n",
    "    - near expiration date ( lower sales )\n",
    "    - new product launches ( lowers sales compared to old known products )\n",
    "\n",
    "- market (store) conditions : \n",
    "    - location ( traffic , income levels )\n",
    "    - better placement , displays\n",
    "    - shorter wait times \n",
    "\n",
    "- macro :\n",
    "    - competitors prices \n",
    "    - inflation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages\n",
    "\n",
    "loading the essential packages to analyze , transform , visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data manipulation library\n",
    "import numpy as np # scientific computing library\n",
    "import matplotlib.pyplot as plt # basic visualization library\n",
    "import seaborn as sns # advanced visualization library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data \n",
    "\n",
    "- Train.csv: this file includes \"Outcome_Sales\" as the target variable, along with features pertaining to the product, store, and data used to train the model. \n",
    "\n",
    "- Test.csv: the only difference is that the target variable isn't there because we need this data to see if the model can generalize its prediction and, more broadly, to identify issues during the model's evaluation phase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structure and Content\n",
    "\n",
    "I'll be primarly using pandas to manipulate data next to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/Train.csv')\n",
    "test_data = pd.read_csv('data/Test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA - Exploratory Data Analysis\n",
    "\n",
    "- I will be trying to discover data dimension , features and the target variables (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5681, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape\n",
    "\n",
    "# 12 columns in the dataset\n",
    "# 8523 rows in the dataset\n",
    "\n",
    "test_data.shape\n",
    "\n",
    "# 11 columns in the dataset ( Item_Outlet_Sales is the target variable )\n",
    "# 5681 rows in the dataset ( about 1/3 of the train data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of the train and test data to avoid modifying the original data\n",
    "train_copy = train_data.copy()\n",
    "test_copy = test_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features\n",
    "\n",
    "12 features , I need to discover their type , content ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility',\n",
       "       'Item_Type', 'Item_MRP', 'Outlet_Identifier',\n",
       "       'Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type',\n",
       "       'Outlet_Type', 'Item_Outlet_Sales'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_copy.info()\n",
    "\n",
    "train_copy.columns\n",
    "# first 5 rows of Item_visibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Item_Weight and Outlet_Size have missing values cause they lack values in the non-null count\n",
    "\n",
    "- categorical features : \n",
    "  - Item_Fat_Content\n",
    "  - Item_Type\n",
    "  - Outlet Type\n",
    "  - Outlet Size \n",
    "  - Outlet_Location_Type\n",
    "\n",
    "- numerical features : \n",
    "  - Item_Visibility\n",
    "  - Item_Weight\n",
    "  - Item_MRP\n",
    "  - Item_Identifier\n",
    "  - Outlet_Identifier\n",
    "  - Outlet_Establishment_Year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8523, 13)\n",
      "Index(['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility',\n",
      "       'Item_Type', 'Item_MRP', 'Outlet_Identifier',\n",
      "       'Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type',\n",
      "       'Outlet_Type', 'Item_Outlet_Sales', 'source'],\n",
      "      dtype='object')\n",
      "(5681, 13)\n",
      "Index(['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility',\n",
      "       'Item_Type', 'Item_MRP', 'Outlet_Identifier',\n",
      "       'Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type',\n",
      "       'Outlet_Type', 'Item_Outlet_Sales', 'source'],\n",
      "      dtype='object')\n",
      "(14204, 13)\n"
     ]
    }
   ],
   "source": [
    "# Merging the Train and Test data to perform data Exploration\n",
    "train_copy['source'] = 'train' # creating a new column in the train data and setting it to 'train'\n",
    "# the reason for this is to be able to separate the train and test data after merging\n",
    "\n",
    "# adding a column 'Item_Outlet_Sales' to the test data and setting it to 0\n",
    "test_copy['Item_Outlet_Sales'] = 0\n",
    "test_copy['source'] = 'test'\n",
    "\n",
    "# merging the train and test data\n",
    "data = pd.concat([train_copy, test_copy], sort = False) # preserve the order of the train and test data\n",
    "\n",
    "\n",
    "print(train_copy.shape)\n",
    "print(train_copy.columns) # 13 columns because source was added\n",
    "print(test_copy.shape)\n",
    "print(test_copy.columns) # 13 columns because source and Item_Outlet_Sales were added\n",
    "print(data.shape) # (14204, 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data \n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discovering the data\n",
    "\n",
    "data.head()\n",
    "data.describe()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for missing values\n",
    "data.isnull().sum()\n",
    "# there are missing values in 'Item_Weight' and 'Outlet_Size' columns\n",
    "# we will fill the missing values in 'Item_Weight' with the mean of the column\n",
    "# and the missing values in 'Outlet_Size' with the mode of the column\n",
    "data['Item_Weight'].fillna(data['Item_Weight'].mean(), inplace=True)\n",
    "data['Outlet_Size'].fillna(data['Outlet_Size'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigMart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
