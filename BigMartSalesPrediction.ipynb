{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement \n",
    "\n",
    "In order to forecast the sales of each product at a specific store, BigMart Sales Prediction aims to comprehend the characteristics of products and how they interact with factors unique to each store.\n",
    "\n",
    "### Goal : \n",
    "\n",
    "Predict the sales of a product at a particular store so it would help :\n",
    "\n",
    "- enhance inventory management\n",
    "- increase sales \n",
    "- marketing decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Generation \n",
    "\n",
    "> Brainstorming the factors that affect the outcome.    \n",
    "\n",
    "- consumer behaviour : \n",
    "    - age , income and family size\n",
    "    - loyalty programs\n",
    "    - maketing campaigns\n",
    "    - online reviews\n",
    "\n",
    "- product :\n",
    "    - higher brand recognition ( higher sales )\n",
    "    - near expiration date ( lower sales )\n",
    "    - new product launches ( lowers sales compared to old known products )\n",
    "\n",
    "- market (store) conditions : \n",
    "    - location ( traffic , income levels )\n",
    "    - better placement , displays\n",
    "    - shorter wait times \n",
    "\n",
    "- macro :\n",
    "    - competitors prices \n",
    "    - inflation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages\n",
    "\n",
    "loading the essential packages to analyze , transform , visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26767/3436009767.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd # data manipulation library\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # data manipulation library\n",
    "import numpy as np # scientific computing library\n",
    "import matplotlib.pyplot as plt # basic visualization library\n",
    "import seaborn as sns # advanced visualization library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data \n",
    "\n",
    "- Train.csv: this file includes \"Outcome_Sales\" as the target variable, along with features pertaining to the product, store, and data used to train the model. \n",
    "\n",
    "- Test.csv: the only difference is that the target variable isn't there because we need this data to see if the model can generalize its prediction and, more broadly, to identify issues during the model's evaluation phase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structure and Content\n",
    "\n",
    "I'll be primarly using pandas to manipulate data next to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/Train.csv')\n",
    "test_data = pd.read_csv('data/Test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA - Exploratory Data Analysis\n",
    "\n",
    "- I will be trying to discover data dimension , features and the target variables (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5681, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape\n",
    "\n",
    "# 12 columns in the dataset\n",
    "# 8523 rows in the dataset\n",
    "\n",
    "test_data.shape\n",
    "\n",
    "# 11 columns in the dataset ( Item_Outlet_Sales is the target variable )\n",
    "# 5681 rows in the dataset ( about 1/3 of the train data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data \n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discovering the data\n",
    "\n",
    "data.head()\n",
    "data.describe()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for missing values\n",
    "data.isnull().sum()\n",
    "# there are missing values in 'Item_Weight' and 'Outlet_Size' columns\n",
    "# we will fill the missing values in 'Item_Weight' with the mean of the column\n",
    "# and the missing values in 'Outlet_Size' with the mode of the column\n",
    "data['Item_Weight'].fillna(data['Item_Weight'].mean(), inplace=True)\n",
    "data['Outlet_Size'].fillna(data['Outlet_Size'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigMart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
