{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement \n",
    "\n",
    "In order to forecast the sales of each product at a specific store, BigMart Sales Prediction aims to comprehend the characteristics of products and how they interact with factors unique to each store.\n",
    "\n",
    "### Goal : \n",
    "\n",
    "Predict the sales of a product at a particular store so it would help :\n",
    "\n",
    "- enhance inventory management\n",
    "- increase sales \n",
    "- marketing decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Generation \n",
    "\n",
    "> Brainstorming the factors that affect the outcome.    \n",
    "\n",
    "- consumer behaviour : \n",
    "    - age , income and family size\n",
    "    - loyalty programs\n",
    "    - maketing campaigns\n",
    "    - online reviews\n",
    "\n",
    "- product :\n",
    "    - higher brand recognition ( higher sales )\n",
    "    - near expiration date ( lower sales )\n",
    "    - new product launches ( lowers sales compared to old known products )\n",
    "\n",
    "- market (store) conditions : \n",
    "    - location ( traffic , income levels )\n",
    "    - better placement , displays\n",
    "    - shorter wait times \n",
    "\n",
    "- macro :\n",
    "    - competitors prices \n",
    "    - inflation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages\n",
    "\n",
    "loading the essential packages to analyze , transform , visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data manipulation library\n",
    "import numpy as np # scientific computing library\n",
    "import matplotlib.pyplot as plt # basic visualization library\n",
    "import seaborn as sns # advanced visualization library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data \n",
    "\n",
    "- Train.csv: this file includes \"Outcome_Sales\" as the target variable, along with features pertaining to the product, store, and data used to train the model. \n",
    "\n",
    "- Test.csv: the only difference is that the target variable isn't there because we need this data to see if the model can generalize its prediction and, more broadly, to identify issues during the model's evaluation phase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structure and Content\n",
    "\n",
    "I'll be primarly using pandas to manipulate data next to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/Train.csv')\n",
    "test_data = pd.read_csv('data/Test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA - Exploratory Data Analysis\n",
    "\n",
    "- I will be trying to discover data dimension , features and the target variables (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5681, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape\n",
    "\n",
    "# 12 columns in the dataset\n",
    "# 8523 rows in the dataset\n",
    "\n",
    "test_data.shape\n",
    "\n",
    "# 11 columns in the dataset ( Item_Outlet_Sales is the target variable )\n",
    "# 5681 rows in the dataset ( about 1/3 of the train data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of the train and test data to avoid modifying the original data\n",
    "train_copy = train_data.copy()\n",
    "test_copy = test_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features\n",
    "\n",
    "12 features , I need to discover their type , content ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8523 entries, 0 to 8522\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Item_Identifier            8523 non-null   object \n",
      " 1   Item_Weight                7060 non-null   float64\n",
      " 2   Item_Fat_Content           8523 non-null   object \n",
      " 3   Item_Visibility            8523 non-null   float64\n",
      " 4   Item_Type                  8523 non-null   object \n",
      " 5   Item_MRP                   8523 non-null   float64\n",
      " 6   Outlet_Identifier          8523 non-null   object \n",
      " 7   Outlet_Establishment_Year  8523 non-null   int64  \n",
      " 8   Outlet_Size                6113 non-null   object \n",
      " 9   Outlet_Location_Type       8523 non-null   object \n",
      " 10  Outlet_Type                8523 non-null   object \n",
      " 11  Item_Outlet_Sales          8523 non-null   float64\n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 799.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_copy.info()\n",
    "\n",
    "# Item_Weight and Outlet_Size have missing values cause they lack values in the non-null count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data \n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discovering the data\n",
    "\n",
    "data.head()\n",
    "data.describe()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for missing values\n",
    "data.isnull().sum()\n",
    "# there are missing values in 'Item_Weight' and 'Outlet_Size' columns\n",
    "# we will fill the missing values in 'Item_Weight' with the mean of the column\n",
    "# and the missing values in 'Outlet_Size' with the mode of the column\n",
    "data['Item_Weight'].fillna(data['Item_Weight'].mean(), inplace=True)\n",
    "data['Outlet_Size'].fillna(data['Outlet_Size'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigMart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
